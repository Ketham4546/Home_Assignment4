{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "import nltk\n",
        "\n",
        "# Remove the nltk_data folder (be careful with this)\n",
        "nltk_data_path = os.path.expanduser('~/nltk_data')\n",
        "if os.path.exists(nltk_data_path):\n",
        "    shutil.rmtree(nltk_data_path)\n",
        "\n",
        "# Re-download cleanly\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJrPL-eO7eaX",
        "outputId": "583c3f97-61aa-47da-f175-98ce680b8733"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If not already installed: pip install spacy\n",
        "# And download the English model: python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Load spaCy English pipeline\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def nlp_preprocessing_spacy(sentence):\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    # Step 1: Tokenization\n",
        "    tokens = [token.text for token in doc]\n",
        "    print(\"Original Tokens:\", tokens)\n",
        "\n",
        "    # Step 2: Remove stopwords and punctuation\n",
        "    tokens_without_stopwords = [token.text for token in doc if not token.is_stop and token.is_alpha]\n",
        "    print(\"Tokens Without Stopwords:\", tokens_without_stopwords)\n",
        "\n",
        "    # Step 3: Stemming\n",
        "    stemmed_words = [stemmer.stem(word) for word in tokens_without_stopwords]\n",
        "    print(\"Stemmed Words:\", stemmed_words)\n",
        "\n",
        "# Example\n",
        "sentence = \"NLP techniques are used in virtual assistants like Alexa and Siri.\"\n",
        "nlp_preprocessing_spacy(sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IiZ4Qfv7j3P",
        "outputId": "9bab8938-074f-490f-d41f-1eaad392edf5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens: ['NLP', 'techniques', 'are', 'used', 'in', 'virtual', 'assistants', 'like', 'Alexa', 'and', 'Siri', '.']\n",
            "Tokens Without Stopwords: ['NLP', 'techniques', 'virtual', 'assistants', 'like', 'Alexa', 'Siri']\n",
            "Stemmed Words: ['nlp', 'techniqu', 'virtual', 'assist', 'like', 'alexa', 'siri']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is the difference between stemming and lemmatization?\n",
        "Stemming chops off word endings to get the root form, which may not be a real word.\n",
        "Lemmatization returns the dictionary base form (lemma) of a word, always valid.\n",
        "\n",
        "Example with “running”:\n",
        "\n",
        "Stemming: \"running\" → \"runn\"\n",
        "\n",
        "Lemmatization: \"running\" → \"run\"\n",
        "\n",
        "2. Why might removing stop words be useful, and when might it be harmful?\n",
        "Useful: It removes common words (like “the”, “is”) that don’t carry much meaning, helping in tasks like text classification or topic modeling.\n",
        "Harmful: In tasks like machine translation or question answering, stop words are important for grammar and meaning, so removing them can hurt performance."
      ],
      "metadata": {
        "id": "8WYL4fjG7uiu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eyasTgsJn2UX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}